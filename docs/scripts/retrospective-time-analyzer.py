#!/usr/bin/env python3
"""
äº‹å¾Œæ™‚é–“åˆ†æå·¥å…· - åŸºæ–¼å¯¦éš›æ™‚é–“æˆ³è­‰æ“šåˆ†æé–‹ç™¼æ™‚é–“
é¿å…ç·¨é€ ï¼Œåªä½¿ç”¨å¯é©—è­‰çš„æ•¸æ“š
"""

import os
import sys
import subprocess
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import argparse

class RetrospectiveTimeAnalyzer:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        
    def run_command(self, command: List[str]) -> Tuple[int, str, str]:
        """åŸ·è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                cwd=self.project_root
            )
            return result.returncode, result.stdout, result.stderr
        except Exception as e:
            return 1, "", str(e)
    
    def get_related_commits(self, keywords: List[str], hours: int = 2) -> List[Dict]:
        """ç²å–ç›¸é—œçš„ git commits"""
        print(f"ğŸ” æœå°‹ç›¸é—œ commitsï¼ˆé—œéµè©: {keywords}ï¼Œæ™‚é–“çª—å£: {hours}å°æ™‚ï¼‰")
        
        # ç²å–æœ€è¿‘çš„ commits
        since_time = (datetime.now() - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M')
        code, stdout, stderr = self.run_command([
            "git", "log", f"--since={since_time}",
            "--pretty=format:%h|%ct|%s", "--no-merges"
        ])
        
        if code != 0:
            print(f"âŒ Git log å¤±æ•—: {stderr}")
            return []
        
        commits = []
        for line in stdout.strip().split('\n'):
            if not line:
                continue
                
            try:
                hash_short, timestamp, message = line.split('|', 2)
                commit_time = datetime.fromtimestamp(int(timestamp))
                
                # æª¢æŸ¥æ˜¯å¦èˆ‡é—œéµè©ç›¸é—œ
                message_lower = message.lower()
                if any(keyword.lower() in message_lower for keyword in keywords):
                    commits.append({
                        'hash': hash_short,
                        'timestamp': commit_time,
                        'message': message,
                        'time_str': commit_time.strftime('%H:%M:%S')
                    })
            except ValueError:
                continue
        
        commits.sort(key=lambda x: x['timestamp'])
        print(f"ğŸ“‹ ç™¼ç¾ {len(commits)} å€‹ç›¸é—œ commits")
        for commit in commits:
            print(f"   {commit['hash']} {commit['time_str']} {commit['message']}")
        
        return commits
    
    def get_related_file_changes(self, keywords: List[str], hours: int = 2) -> List[Dict]:
        """ç²å–ç›¸é—œçš„æª”æ¡ˆè®Šæ›´"""
        print(f"ğŸ“ æœå°‹ç›¸é—œæª”æ¡ˆè®Šæ›´")
        
        file_changes = []
        
        # æœå°‹åŒ…å«é—œéµè©çš„æª”æ¡ˆ
        for keyword in keywords:
            # åœ¨ docs ç›®éŒ„ä¸­æœå°‹ç›¸é—œæª”æ¡ˆ
            for pattern in [f"*{keyword}*", f"*{keyword.upper()}*", f"*{keyword.lower()}*"]:
                code, stdout, stderr = self.run_command([
                    "find", "docs", "-name", pattern, "-type", "f"
                ])
                
                if code == 0:
                    for file_path in stdout.strip().split('\n'):
                        if file_path and Path(file_path).exists():
                            # ç²å–æª”æ¡ˆä¿®æ”¹æ™‚é–“
                            stat_result = os.stat(file_path)
                            mod_time = datetime.fromtimestamp(stat_result.st_mtime)
                            
                            # æª¢æŸ¥æ˜¯å¦åœ¨æ™‚é–“çª—å£å…§
                            cutoff = datetime.now() - timedelta(hours=hours)
                            if mod_time > cutoff:
                                file_changes.append({
                                    'path': file_path,
                                    'modified_time': mod_time,
                                    'time_str': mod_time.strftime('%H:%M:%S'),
                                    'keyword': keyword
                                })
        
        # å»é‡å’Œæ’åº
        unique_files = {}
        for change in file_changes:
            path = change['path']
            if path not in unique_files or change['modified_time'] > unique_files[path]['modified_time']:
                unique_files[path] = change
        
        file_changes = list(unique_files.values())
        file_changes.sort(key=lambda x: x['modified_time'])
        
        print(f"ğŸ“„ ç™¼ç¾ {len(file_changes)} å€‹ç›¸é—œæª”æ¡ˆ")
        for change in file_changes:
            print(f"   {change['time_str']} {change['path']}")
        
        return file_changes
    
    def get_session_logs(self, hours: int = 2) -> List[Dict]:
        """æª¢æŸ¥æ™‚é–“è¿½è¹¤æ—¥èªŒ"""
        print("â° æª¢æŸ¥æ™‚é–“è¿½è¹¤æ—¥èªŒ")
        
        today = datetime.now().strftime('%Y-%m-%d')
        sessions_dir = self.project_root / "docs" / "time-logs" / "sessions" / today
        
        session_logs = []
        if sessions_dir.exists():
            for session_file in sessions_dir.glob("session_*.json"):
                try:
                    with open(session_file, 'r', encoding='utf-8') as f:
                        session_data = json.load(f)
                    
                    metrics = session_data.get('session_metrics', {})
                    start_time = metrics.get('start_timestamp')
                    if start_time:
                        session_start = datetime.fromisoformat(start_time.replace('Z', '+00:00').replace('+00:00', ''))
                        cutoff = datetime.now() - timedelta(hours=hours)
                        
                        if session_start > cutoff:
                            session_logs.append({
                                'file': str(session_file),
                                'start_time': session_start,
                                'metrics': metrics
                            })
                except Exception as e:
                    print(f"âš ï¸  ç„¡æ³•è®€å– {session_file}: {e}")
        
        print(f"ğŸ“Š ç™¼ç¾ {len(session_logs)} å€‹æ™‚é–“è¿½è¹¤æ—¥èªŒ")
        return session_logs
    
    def calculate_time_range(self, commits: List[Dict], file_changes: List[Dict]) -> Dict:
        """è¨ˆç®—æ™‚é–“ç¯„åœ"""
        print("ğŸ“ è¨ˆç®—æ™‚é–“ç¯„åœ")
        
        all_timestamps = []
        
        # æ·»åŠ  commit æ™‚é–“æˆ³
        for commit in commits:
            all_timestamps.append({
                'time': commit['timestamp'],
                'source': f"commit {commit['hash']}",
                'type': 'commit'
            })
        
        # æ·»åŠ æª”æ¡ˆè®Šæ›´æ™‚é–“æˆ³
        for change in file_changes:
            all_timestamps.append({
                'time': change['modified_time'], 
                'source': f"file {Path(change['path']).name}",
                'type': 'file'
            })
        
        if not all_timestamps:
            return {
                'duration_minutes': None,
                'start_time': None,
                'end_time': None,
                'reliable': False,
                'evidence_count': 0
            }
        
        # æ’åºæ™‚é–“æˆ³
        all_timestamps.sort(key=lambda x: x['time'])
        
        start_time = all_timestamps[0]['time']
        end_time = all_timestamps[-1]['time']
        duration = end_time - start_time
        duration_minutes = duration.total_seconds() / 60
        
        print(f"â±ï¸  æ™‚é–“ç¯„åœ:")
        print(f"   é–‹å§‹: {start_time.strftime('%H:%M:%S')} ({all_timestamps[0]['source']})")
        print(f"   çµæŸ: {end_time.strftime('%H:%M:%S')} ({all_timestamps[-1]['source']})")
        print(f"   ç¸½æ™‚é–“: {duration_minutes:.1f} åˆ†é˜")
        print(f"   è­‰æ“šæ•¸é‡: {len(all_timestamps)} å€‹æ™‚é–“æˆ³")
        
        return {
            'duration_minutes': round(duration_minutes, 1),
            'start_time': start_time,
            'end_time': end_time,
            'reliable': len(all_timestamps) >= 2,
            'evidence_count': len(all_timestamps),
            'evidence': all_timestamps
        }
    
    def validate_consistency(self, commits: List[Dict], file_changes: List[Dict], 
                           session_logs: List[Dict]) -> str:
        """é©—è­‰æ•¸æ“šä¸€è‡´æ€§"""
        print("ğŸ” é©—è­‰æ•¸æ“šä¸€è‡´æ€§")
        
        evidence_count = len(commits) + len(file_changes) + len(session_logs)
        
        if evidence_count >= 3:
            confidence = "high"
        elif evidence_count >= 2:
            confidence = "medium"
        elif evidence_count >= 1:
            confidence = "low"
        else:
            confidence = "none"
        
        print(f"ğŸ¯ ä¿¡å¿ƒç­‰ç´š: {confidence}")
        print(f"   Commits: {len(commits)}")
        print(f"   æª”æ¡ˆè®Šæ›´: {len(file_changes)}")
        print(f"   æ™‚é–“æ—¥èªŒ: {len(session_logs)}")
        
        return confidence
    
    def get_verification_commands(self, keywords: List[str]) -> List[str]:
        """ç”Ÿæˆé©—è­‰å‘½ä»¤"""
        commands = [
            'git log --pretty=format:"%h %cd %s" --date=format:"%H:%M:%S" -10',
        ]
        
        for keyword in keywords:
            commands.append(f'find docs -name "*{keyword}*" -exec stat -f "%N: %Sm" -t "%H:%M:%S" {{}} \\;')
        
        return commands
    
    def analyze_task_time(self, keywords: List[str], hours: int = 2) -> Dict:
        """åˆ†æç‰¹å®šä»»å‹™çš„é–‹ç™¼æ™‚é–“"""
        print(f"ğŸ•’ é–‹å§‹äº‹å¾Œæ™‚é–“åˆ†æ")
        print(f"ğŸ“‹ ä»»å‹™é—œéµè©: {keywords}")
        print(f"â° æ™‚é–“çª—å£: {hours} å°æ™‚")
        print("="*50)
        
        # 1. æ”¶é›†è­‰æ“š
        commits = self.get_related_commits(keywords, hours)
        file_changes = self.get_related_file_changes(keywords, hours)
        session_logs = self.get_session_logs(hours)
        
        # 2. è¨ˆç®—æ™‚é–“ç¯„åœ
        time_range = self.calculate_time_range(commits, file_changes)
        
        # 3. é©—è­‰ä¸€è‡´æ€§
        confidence = self.validate_consistency(commits, file_changes, session_logs)
        
        # 4. ç”Ÿæˆå ±å‘Š
        if session_logs and confidence != "none":
            # å„ªå…ˆä½¿ç”¨çœŸå¯¦æ™‚é–“è¿½è¹¤
            latest_session = max(session_logs, key=lambda x: x['start_time'])
            metrics = latest_session['metrics']
            
            result = {
                'total_time_minutes': metrics.get('total_time_minutes'),
                'ai_time_minutes': metrics.get('ai_time_minutes'),
                'human_time_minutes': metrics.get('human_time_minutes'),
                'time_estimation_method': 'retrospective_real_time_logs',
                'is_real_time': True,
                'data_quality': 'high',
                'confidence_level': confidence,
                'evidence': {
                    'session_logs': session_logs,
                    'git_commits': commits,
                    'file_changes': file_changes
                }
            }
        elif time_range['reliable']:
            # ä½¿ç”¨æ™‚é–“æˆ³åˆ†æ
            result = {
                'total_time_minutes': time_range['duration_minutes'],
                'time_estimation_method': 'retrospective_timestamp_analysis',
                'is_real_time': False,
                'data_quality': 'high' if confidence in ['high', 'medium'] else 'medium',
                'confidence_level': confidence,
                'evidence': {
                    'git_commits': commits,
                    'file_changes': file_changes,
                    'time_range': time_range
                }
            }
        else:
            # æ•¸æ“šä¸è¶³
            result = {
                'total_time_minutes': None,
                'time_estimation_method': 'insufficient_evidence',
                'is_real_time': False,
                'data_quality': 'insufficient',
                'confidence_level': 'none',
                'evidence': {
                    'git_commits': commits,
                    'file_changes': file_changes
                },
                'recommendation': 'use_file_count_estimate_with_warning'
            }
        
        # 5. æ·»åŠ é©—è­‰ä¿¡æ¯
        result['verification_commands'] = self.get_verification_commands(keywords)
        result['analysis_timestamp'] = datetime.now().isoformat()
        
        return result
    
    def print_analysis_report(self, result: Dict, keywords: List[str]):
        """åˆ—å°åˆ†æå ±å‘Š"""
        print("\n" + "="*50)
        print("ğŸ“Š äº‹å¾Œæ™‚é–“åˆ†æå ±å‘Š")
        print("="*50)
        
        print(f"ğŸ¯ ä»»å‹™: {', '.join(keywords)}")
        print(f"â° é–‹ç™¼æ™‚é–“: {result.get('total_time_minutes', 'ç„¡æ³•ç¢ºå®š')} åˆ†é˜")
        print(f"ğŸ“Š æ•¸æ“šå“è³ª: {result.get('data_quality', 'unknown')}")
        print(f"ğŸ¯ ä¿¡å¿ƒç­‰ç´š: {result.get('confidence_level', 'unknown')}")
        print(f"ğŸ“‹ åˆ†ææ–¹æ³•: {result.get('time_estimation_method', 'unknown')}")
        
        if result.get('verification_commands'):
            print(f"\nğŸ” é©—è­‰å‘½ä»¤:")
            for cmd in result['verification_commands']:
                print(f"   {cmd}")
        
        print("="*50)

def main():
    parser = argparse.ArgumentParser(description='äº‹å¾Œæ™‚é–“åˆ†æå·¥å…·')
    parser.add_argument('--task', required=True, help='ä»»å‹™é—œéµè©ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰')
    parser.add_argument('--hours', type=int, default=2, help='æ™‚é–“çª—å£ï¼ˆå°æ™‚ï¼‰')
    parser.add_argument('--output', help='è¼¸å‡ºæª”æ¡ˆè·¯å¾‘')
    
    args = parser.parse_args()
    
    keywords = [k.strip() for k in args.task.split(',')]
    
    analyzer = RetrospectiveTimeAnalyzer()
    result = analyzer.analyze_task_time(keywords, args.hours)
    analyzer.print_analysis_report(result, keywords)
    
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False, default=str)
        print(f"\nğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {args.output}")

if __name__ == "__main__":
    main()