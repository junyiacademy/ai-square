#!/usr/bin/env python3
"""
Smart Ticket Creator
æ™ºèƒ½åˆ†æ commits ä¸¦è‡ªå‹•åˆ¤æ–·é¡å‹ã€åˆç†åˆ†çµ„å‰µå»ºç¥¨åˆ¸
"""

import os
import yaml
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import re
from collections import defaultdict

class SmartTicketCreator:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.tickets_dir = self.project_root / "docs" / "tickets"
        self.active_dir = self.tickets_dir / "active"
        
        # Commit é¡å‹æ˜ å°„
        self.type_patterns = {
            'feature': [r'^feat(\(.*?\))?:', r'^feature:', r'add', r'implement', r'create'],
            'fix': [r'^fix(\(.*?\))?:', r'^bugfix:', r'^hotfix:', r'resolve', r'repair'],
            'chore': [r'^chore(\(.*?\))?:', r'^build:', r'^ci:', r'update', r'cleanup'],
            'refactor': [r'^refactor(\(.*?\))?:', r'restructure', r'reorganize'],
            'docs': [r'^docs(\(.*?\))?:', r'documentation', r'readme'],
            'test': [r'^test(\(.*?\))?:', r'testing', r'tests'],
            'style': [r'^style(\(.*?\))?:', r'formatting', r'lint']
        }
        
    def detect_commit_type(self, message: str) -> str:
        """å¾ commit message è‡ªå‹•åˆ¤æ–·é¡å‹"""
        message_lower = message.lower()
        
        for commit_type, patterns in self.type_patterns.items():
            for pattern in patterns:
                if re.search(pattern, message_lower):
                    return commit_type if commit_type in ['feature', 'fix', 'chore'] else 'chore'
        
        return 'feature'  # é è¨­é¡å‹
    
    def should_group_commits(self, commits: List[Dict]) -> bool:
        """åˆ¤æ–·é€™äº› commits æ˜¯å¦æ‡‰è©²è¢«åˆ†çµ„"""
        if len(commits) <= 1:
            return False
            
        # æª¢æŸ¥æ™‚é–“ç¯„åœï¼ˆ4å°æ™‚å…§çš„è¦–ç‚ºåŒä¸€æ‰¹å·¥ä½œï¼‰
        times = [datetime.fromisoformat(c['timestamp'].replace(' +0800', '+08:00')) for c in commits]
        time_diff = (max(times) - min(times)).total_seconds() / 3600
        
        if time_diff > 4:
            return False
            
        # æª¢æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼çš„ commit message æ¨¡å¼
        messages = [c['message'].lower() for c in commits]
        
        # ç›¸ä¼¼åº¦æª¢æŸ¥
        common_words = set()
        for msg in messages:
            words = set(re.findall(r'\b\w+\b', msg))
            if not common_words:
                common_words = words
            else:
                common_words &= words
        
        # å¦‚æœæœ‰å…±åŒçš„é—œéµå­—ï¼ˆæ’é™¤å¸¸è¦‹è©ï¼‰
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'fix', 'update'}
        common_words -= stop_words
        
        return len(common_words) >= 2
    
    def group_related_commits(self, orphan_commits: List[Dict]) -> List[List[Dict]]:
        """å°‡ç›¸é—œçš„ commits æ™ºèƒ½åˆ†çµ„"""
        groups = []
        used_commits = set()
        
        # æŒ‰æ™‚é–“æ’åº
        sorted_commits = sorted(orphan_commits, 
                              key=lambda x: datetime.fromisoformat(x['timestamp'].replace(' +0800', '+08:00')))
        
        for i, commit in enumerate(sorted_commits):
            if commit['hash'] in used_commits:
                continue
                
            # æ”¶é›†å¯èƒ½ç›¸é—œçš„ commits
            potential_group = [commit]
            commit_time = datetime.fromisoformat(commit['timestamp'].replace(' +0800', '+08:00'))
            
            # å‘å¾ŒæŸ¥æ‰¾ç›¸é—œ commitsï¼ˆ4å°æ™‚å…§ï¼‰
            for j in range(i + 1, len(sorted_commits)):
                next_commit = sorted_commits[j]
                if next_commit['hash'] in used_commits:
                    continue
                    
                next_time = datetime.fromisoformat(next_commit['timestamp'].replace(' +0800', '+08:00'))
                time_diff = (next_time - commit_time).total_seconds() / 3600
                
                if time_diff <= 4:
                    # æª¢æŸ¥æ˜¯å¦ç›¸é—œ
                    if self.are_commits_related(commit, next_commit):
                        potential_group.append(next_commit)
            
            # åˆ¤æ–·æ˜¯å¦æ‡‰è©²åˆ†çµ„
            if self.should_group_commits(potential_group):
                groups.append(potential_group)
                for c in potential_group:
                    used_commits.add(c['hash'])
            else:
                # å–®ç¨æˆçµ„
                groups.append([commit])
                used_commits.add(commit['hash'])
        
        return groups
    
    def are_commits_related(self, commit1: Dict, commit2: Dict) -> bool:
        """åˆ¤æ–·å…©å€‹ commits æ˜¯å¦ç›¸é—œ"""
        msg1 = commit1['message'].lower()
        msg2 = commit2['message'].lower()
        
        # 1. æª¢æŸ¥æ˜¯å¦ä¿®æ”¹ç›¸åŒæª”æ¡ˆ
        files1 = set(commit1.get('files', []))
        files2 = set(commit2.get('files', []))
        if files1 & files2:  # æœ‰äº¤é›†
            return True
        
        # 2. æª¢æŸ¥ message ç›¸ä¼¼åº¦
        words1 = set(re.findall(r'\b\w+\b', msg1))
        words2 = set(re.findall(r'\b\w+\b', msg2))
        
        # ç§»é™¤å¸¸è¦‹è©
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}
        words1 -= stop_words
        words2 -= stop_words
        
        # è¨ˆç®— Jaccard ç›¸ä¼¼åº¦
        if words1 and words2:
            similarity = len(words1 & words2) / len(words1 | words2)
            if similarity > 0.3:
                return True
        
        # 3. æª¢æŸ¥æ˜¯å¦å±¬æ–¼åŒä¸€åŠŸèƒ½æ¨¡çµ„
        # ä¾‹å¦‚éƒ½æ˜¯ "fix:" æˆ–éƒ½æ˜¯ "feat:"
        type1 = self.detect_commit_type(msg1)
        type2 = self.detect_commit_type(msg2)
        
        if type1 == type2 and type1 != 'chore':
            # é€²ä¸€æ­¥æª¢æŸ¥æ˜¯å¦åœ¨è™•ç†ç›¸åŒçš„åŠŸèƒ½
            if any(word in msg2 for word in ['continue', 'more', 'additional', 'further']):
                return True
        
        return False
    
    def get_commit_details(self, commit_hash: str) -> Dict:
        """ç²å– commit çš„è©³ç´°è³‡è¨Š"""
        # ç²å–ä¿®æ”¹çš„æª”æ¡ˆ
        cmd_files = ["git", "show", "--name-only", "--format=", commit_hash]
        files_result = subprocess.run(cmd_files, capture_output=True, text=True, cwd=self.project_root)
        files = [f for f in files_result.stdout.strip().split('\n') if f]
        
        return {'files': files}
    
    def create_grouped_ticket(self, commits_group: List[Dict], ticket_type: str = None) -> str:
        """ç‚ºä¸€çµ„ç›¸é—œçš„ commits å‰µå»ºç¥¨åˆ¸"""
        # è‡ªå‹•åˆ¤æ–·é¡å‹
        if not ticket_type:
            types = [self.detect_commit_type(c['message']) for c in commits_group]
            ticket_type = max(set(types), key=types.count)  # æœ€å¸¸è¦‹çš„é¡å‹
        
        # ç”Ÿæˆç¥¨åˆ¸æ¨™é¡Œ
        if len(commits_group) == 1:
            title = commits_group[0]['message']
        else:
            # æå–å…±åŒä¸»é¡Œ
            messages = [c['message'] for c in commits_group]
            title = self.extract_common_theme(messages)
        
        # æ•´ç†ç¥¨åˆ¸åç¨±
        ticket_name = re.sub(r'^(feat|fix|chore|refactor|docs|style|test)(\(.+?\))?: ', '', title)
        ticket_name = re.sub(r'[^a-zA-Z0-9\s-]', '', ticket_name).strip()
        ticket_name = re.sub(r'\s+', '-', ticket_name.lower())[:40]
        
        # å‰µå»ºç¥¨åˆ¸æª”æ¡ˆ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}-{ticket_type}-{ticket_name}.yml"
        filepath = self.active_dir / filename
        
        # æ”¶é›†æ‰€æœ‰è³‡è¨Š
        all_files = set()
        total_duration = 0
        activities = []
        commit_hashes = []
        
        # æ™‚é–“ç¯„åœ
        times = [datetime.fromisoformat(c['timestamp'].replace(' +0800', '+08:00')) for c in commits_group]
        start_time = min(times)
        end_time = max(times)
        
        for commit in commits_group:
            # ç²å–æª”æ¡ˆè³‡è¨Š
            details = self.get_commit_details(commit['hash'])
            all_files.update(details['files'])
            
            # æ”¶é›†æ´»å‹•
            activities.append(f"- {commit['message']} ({commit['hash'][:8]})")
            commit_hashes.append(commit['hash'][:8])
            
            # ä¼°ç®—æ™‚é–“ï¼ˆæ¯å€‹ commit 15-30 åˆ†é˜ï¼‰
            total_duration += 20
        
        # å¦‚æœæ™‚é–“è·¨åº¦å¾ˆå¤§ï¼Œä½¿ç”¨å¯¦éš›æ™‚é–“å·®
        actual_duration = int((end_time - start_time).total_seconds() / 60)
        if actual_duration > total_duration:
            total_duration = min(actual_duration, 240)  # æœ€å¤š 4 å°æ™‚
        
        # ä¼°ç®—è¤‡é›œåº¦å’Œæˆæœ¬
        complexity = self.estimate_complexity(len(all_files), len(commits_group))
        cost_map = {"simple": 0.05, "medium": 0.15, "complex": 0.25}
        estimated_cost = cost_map.get(complexity, 0.15) * len(commits_group)
        
        # å‰µå»ºç¥¨åˆ¸å…§å®¹
        ticket_data = {
            'spec': {
                'feature': title,
                'purpose': f"Grouped {len(commits_group)} related commits",
                'commits_grouped': commit_hashes,
                'created_from_commits': True
            },
            'dev_log': {
                'sessions': [{
                    'session_id': 1,
                    'date': start_time.strftime('%Y-%m-%d'),
                    'start_time': start_time.strftime('%H:%M:%S'),
                    'end_time': end_time.strftime('%H:%M:%S'),
                    'duration_minutes': total_duration,
                    'activities': activities,
                    'files_modified': list(all_files),
                    'decisions': [f"Grouped {len(commits_group)} related commits into single ticket"],
                    'challenges': [],
                    'next_steps': []
                }]
            },
            'test_report': {
                'test_runs': [],
                'final_status': 'completed'
            },
            'ai_usage': {
                'interactions': [{
                    'timestamp': datetime.now().isoformat(),
                    'task_type': 'development',
                    'description': f'Grouped development - {complexity}',
                    'complexity': complexity,
                    'estimated_cost': estimated_cost
                }],
                'total_interactions': len(commits_group),
                'complexity_breakdown': {f'{complexity}_count': len(commits_group)},
                'estimated_cost_usd': round(estimated_cost, 2)
            },
            'development': {
                'commit_hash': commit_hashes[-1],  # æœ€å¾Œä¸€å€‹ commit
                'all_commits': commit_hashes,
                'branch': 'main',
                'files_modified': list(all_files)
            },
            'time_tracking': {
                'started_at': start_time.isoformat(),
                'completed_at': end_time.isoformat(),
                'actual_duration_minutes': total_duration,
                'ai_time_minutes': int(total_duration * 0.6),
                'human_time_minutes': int(total_duration * 0.4)
            },
            'completion_checklist': {
                'spec_defined': True,
                'code_implemented': True,
                'tests_written': False,
                'tests_passing': False,
                'documentation_updated': False,
                'ai_metrics_recorded': True,
                'story_extracted': False
            },
            'created_at': datetime.now().isoformat(),
            'title': title,
            'description': f"Retroactively created from {len(commits_group)} commits",
            'ticket_type': ticket_type,
            'status': 'completed'
        }
        
        # å¯«å…¥æª”æ¡ˆ
        os.makedirs(self.active_dir, exist_ok=True)
        with open(filepath, 'w', encoding='utf-8') as f:
            yaml.dump(ticket_data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
        
        return str(filepath)
    
    def extract_common_theme(self, messages: List[str]) -> str:
        """å¾å¤šå€‹ commit messages æå–å…±åŒä¸»é¡Œ"""
        # ç§»é™¤å‰ç¶´
        cleaned = []
        for msg in messages:
            cleaned_msg = re.sub(r'^(feat|fix|chore|refactor|docs|style|test)(\(.+?\))?: ', '', msg)
            cleaned.append(cleaned_msg)
        
        # æ‰¾å‡ºæœ€å¸¸è¦‹çš„è©
        word_freq = defaultdict(int)
        for msg in cleaned:
            words = re.findall(r'\b\w+\b', msg.lower())
            for word in words:
                if len(word) > 3:  # å¿½ç•¥çŸ­è©
                    word_freq[word] += 1
        
        # é¸æ“‡æœ€é »ç¹çš„è©æ§‹å»ºæ¨™é¡Œ
        if word_freq:
            top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:3]
            theme_words = [word for word, _ in top_words]
            return f"Multiple updates for {' '.join(theme_words)}"
        
        return f"Grouped {len(messages)} related changes"
    
    def estimate_complexity(self, file_count: int, commit_count: int) -> str:
        """ä¼°ç®—å·¥ä½œè¤‡é›œåº¦"""
        if file_count > 10 or commit_count > 5:
            return "complex"
        elif file_count > 5 or commit_count > 2:
            return "medium"
        else:
            return "simple"
    
    def find_orphan_commits_local(self, days: int = 7) -> List[Dict]:
        """æ‰¾å‡ºæ²’æœ‰å°æ‡‰ç¥¨åˆ¸çš„ commits (æœ¬åœ°å¯¦ç¾)"""
        # ç²å–æ‰€æœ‰ç¥¨åˆ¸çš„ commit hashes
        ticket_commits = set()
        
        for ticket_file in self.tickets_dir.rglob("*.yml"):
            try:
                with open(ticket_file, 'r', encoding='utf-8') as f:
                    ticket = yaml.safe_load(f)
                    if 'development' in ticket and 'commit_hash' in ticket['development']:
                        ticket_commits.add(ticket['development']['commit_hash'][:8])
                    elif 'commit_hash' in ticket:  # èˆŠæ ¼å¼
                        ticket_commits.add(ticket['commit_hash'][:8])
            except:
                pass
        
        # ç²å–æœ€è¿‘çš„ commits
        cmd = ["git", "log", f"--since={days} days ago", "--format=%H|%ai|%s"]
        result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.project_root)
        
        orphan_commits = []
        for line in result.stdout.strip().split('\n'):
            if line:
                hash, date, message = line.split('|', 2)
                short_hash = hash[:8]
                
                # è·³é merge commits å’Œè‡ªå‹• commits
                if 'Merge' in message or 'chore:' in message:
                    continue
                    
                if short_hash not in ticket_commits:
                    orphan_commits.append({
                        'hash': hash,
                        'short_hash': short_hash,
                        'date': date,
                        'message': message,
                        'timestamp': date  # çµ±ä¸€æ¬„ä½å
                    })
        
        return orphan_commits
    
    def analyze_and_create_tickets(self, days: int = 7, dry_run: bool = False) -> None:
        """åˆ†æä¸¦æ™ºèƒ½å‰µå»ºç¥¨åˆ¸"""
        # ç²å–å­¤å…’ commits
        orphan_commits = self.find_orphan_commits_local(days)
        
        if not orphan_commits:
            print("âœ… æ²’æœ‰æ‰¾åˆ°éœ€è¦è£œç¥¨çš„ commits")
            return
        
        # ç‚ºæ¯å€‹ commit ç²å–è©³ç´°è³‡è¨Š
        for commit in orphan_commits:
            details = self.get_commit_details(commit['hash'])
            commit.update(details)
            commit['timestamp'] = commit['date']  # çµ±ä¸€æ¬„ä½åç¨±
        
        # æ™ºèƒ½åˆ†çµ„
        groups = self.group_related_commits(orphan_commits)
        
        print(f"\nğŸ“Š åˆ†æçµæœï¼š")
        print(f"- æ‰¾åˆ° {len(orphan_commits)} å€‹æ²’æœ‰ç¥¨åˆ¸çš„ commits")
        print(f"- æ™ºèƒ½åˆ†çµ„ç‚º {len(groups)} å€‹ç¥¨åˆ¸")
        print("-" * 80)
        
        # é¡¯ç¤ºåˆ†çµ„çµæœ
        for i, group in enumerate(groups, 1):
            ticket_type = self.detect_commit_type(group[0]['message'])
            print(f"\nğŸ“‹ ç¥¨åˆ¸ #{i} ({ticket_type}):")
            
            if len(group) == 1:
                print(f"   å–®ä¸€ commit: {group[0]['hash'][:8]} - {group[0]['message'][:60]}")
            else:
                print(f"   åŒ…å« {len(group)} å€‹ç›¸é—œ commits:")
                for commit in group:
                    print(f"     - {commit['hash'][:8]} {commit['message'][:50]}")
            
            # ä¼°ç®—è³‡è¨Š
            file_count = len(set().union(*[set(c.get('files', [])) for c in group]))
            complexity = self.estimate_complexity(file_count, len(group))
            print(f"   æª”æ¡ˆæ•¸: {file_count}, è¤‡é›œåº¦: {complexity}")
        
        if dry_run:
            print("\nğŸ” Dry run æ¨¡å¼ï¼Œä¸æœƒå¯¦éš›å‰µå»ºç¥¨åˆ¸")
            return
        
        # ç¢ºèªå‰µå»º
        print("\n" + "="*80)
        response = input("æ˜¯å¦å‰µå»ºé€™äº›ç¥¨åˆ¸ï¼Ÿ(y/n/é¸æ“‡ç·¨è™Ÿ): ").strip().lower()
        
        if response == 'n':
            print("âŒ å–æ¶ˆæ“ä½œ")
            return
        elif response == 'y':
            # å‰µå»ºæ‰€æœ‰ç¥¨åˆ¸
            for i, group in enumerate(groups, 1):
                filepath = self.create_grouped_ticket(group)
                print(f"âœ… å‰µå»ºç¥¨åˆ¸ #{i}: {os.path.basename(filepath)}")
        else:
            # é¸æ“‡æ€§å‰µå»º
            try:
                selected = [int(x.strip()) for x in response.split(',')]
                for i in selected:
                    if 1 <= i <= len(groups):
                        filepath = self.create_grouped_ticket(groups[i-1])
                        print(f"âœ… å‰µå»ºç¥¨åˆ¸ #{i}: {os.path.basename(filepath)}")
                    else:
                        print(f"âŒ ç„¡æ•ˆçš„ç·¨è™Ÿ: {i}")
            except ValueError:
                print("âŒ ç„¡æ•ˆçš„è¼¸å…¥")

def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Smart ticket creation from orphan commits')
    parser.add_argument('--days', type=int, default=7, help='Days to look back')
    parser.add_argument('--dry-run', action='store_true', help='Only show analysis without creating tickets')
    
    args = parser.parse_args()
    
    # æ‰¾åˆ°å°ˆæ¡ˆæ ¹ç›®éŒ„
    current_dir = Path.cwd()
    while current_dir != current_dir.parent:
        if (current_dir / '.git').exists():
            break
        current_dir = current_dir.parent
    
    creator = SmartTicketCreator(str(current_dir))
    creator.analyze_and_create_tickets(days=args.days, dry_run=args.dry_run)

if __name__ == "__main__":
    main()