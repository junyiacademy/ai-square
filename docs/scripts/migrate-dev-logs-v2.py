#!/usr/bin/env python3
"""
Enhanced migration script for dev logs
- Better time calculation using git log
- Clearer filename generation
- Option to process specific files or all
"""

import os
import subprocess
import yaml
import re
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class DevLogMigrationV2:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.dev_logs_dir = self.project_root / "docs" / "dev-logs"
        self.migrated_count = 0
        self.error_count = 0
        self.skipped_count = 0
        
    def run_command(self, cmd: List[str]) -> Tuple[int, str, str]:
        """åŸ·è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd=self.project_root
        )
        return result.returncode, result.stdout, result.stderr
    
    def get_commit_time_by_log(self, commit_hash: str) -> Dict:
        """ä½¿ç”¨ git log ç²å–æ›´æº–ç¢ºçš„æ™‚é–“"""
        # ç²å–æœ€è¿‘ 100 å€‹ commits çš„æ™‚é–“è³‡è¨Š
        code, log_output, _ = self.run_command([
            "git", "log", 
            "--pretty=%H %ct %s",  # hash, timestamp, subject
            "-100"
        ])
        
        if code != 0:
            return self._fallback_time_estimate(commit_hash)
        
        # è§£æ log
        commits = []
        for line in log_output.strip().split('\n'):
            parts = line.split(' ', 2)
            if len(parts) >= 3:
                hash_full = parts[0]
                timestamp = int(parts[1])
                subject = parts[2]
                commits.append({
                    'hash': hash_full[:8],
                    'time': datetime.fromtimestamp(timestamp),
                    'subject': subject
                })
        
        # æ‰¾åˆ°ç›®æ¨™ commit
        target_idx = -1
        for i, commit in enumerate(commits):
            if commit['hash'] == commit_hash[:8]:
                target_idx = i
                break
        
        if target_idx == -1:
            return self._fallback_time_estimate(commit_hash)
        
        # è¨ˆç®—èˆ‡å‰ä¸€å€‹ commit çš„æ™‚é–“å·®
        if target_idx < len(commits) - 1:
            current_time = commits[target_idx]['time']
            prev_time = commits[target_idx + 1]['time']
            
            duration = (current_time - prev_time).total_seconds() / 60
            
            # åˆç†æ€§æª¢æŸ¥
            if duration < 1:
                # å¤ªçŸ­ï¼Œå¯èƒ½æ˜¯é€£çºŒ commitï¼ŒæŸ¥çœ‹æ›´å‰é¢çš„
                for j in range(target_idx + 2, min(target_idx + 5, len(commits))):
                    alt_duration = (current_time - commits[j]['time']).total_seconds() / 60
                    if 5 <= alt_duration <= 120:
                        duration = alt_duration
                        break
                else:
                    duration = 10  # é è¨­ 10 åˆ†é˜
            elif duration > 480:  # 8 å°æ™‚
                duration = 60  # é è¨­ 1 å°æ™‚
            
            return {
                'total': round(duration, 1),
                'ai': round(duration * 0.8, 1),
                'human': round(duration * 0.2, 1),
                'method': 'git_log_analysis',
                'confidence': 'high'
            }
        
        return self._fallback_time_estimate(commit_hash)
    
    def _fallback_time_estimate(self, commit_hash: str) -> Dict:
        """åŸºæ–¼æª”æ¡ˆæ•¸é‡çš„å¾Œå‚™ä¼°ç®—"""
        # ç²å–è®Šæ›´æª”æ¡ˆæ•¸
        code, output, _ = self.run_command([
            "git", "show", "--stat", "--format=", commit_hash
        ])
        
        if code == 0:
            lines = output.strip().split('\n')
            # æœ€å¾Œä¸€è¡Œé€šå¸¸æ˜¯çµ±è¨ˆè³‡è¨Š
            if lines and 'changed' in lines[-1]:
                # æå–æª”æ¡ˆæ•¸é‡
                match = re.search(r'(\d+) file', lines[-1])
                if match:
                    file_count = int(match.group(1))
                    
                    if file_count <= 1:
                        duration = 5
                    elif file_count <= 3:
                        duration = 15
                    elif file_count <= 5:
                        duration = 30
                    elif file_count <= 10:
                        duration = 60
                    else:
                        duration = 90
                    
                    return {
                        'total': duration,
                        'ai': round(duration * 0.8, 1),
                        'human': round(duration * 0.2, 1),
                        'method': 'file_count_estimate',
                        'confidence': 'medium'
                    }
        
        return {
            'total': 30,
            'ai': 24,
            'human': 6,
            'method': 'default_fallback',
            'confidence': 'low'
        }
    
    def generate_clear_filename(self, log_data: Dict, commit_hash: str) -> str:
        """ç”Ÿæˆæ›´æ¸…æ™°çš„æª”å"""
        date_str = log_data.get('date', datetime.now().strftime('%Y-%m-%d'))
        commit_type = log_data.get('type', 'other')
        
        # ç²å– commit è¨Šæ¯
        code, message, _ = self.run_command(["git", "log", "-1", "--pretty=%s", commit_hash])
        if code != 0:
            message = log_data.get('title', 'unknown')
        else:
            message = message.strip()
        
        # æå–é—œéµè©
        clean_message = re.sub(r'^[^:()]+[(:][^:)]*[):]?\s*', '', message)
        
        # ç‰¹æ®Šé—œéµè©è™•ç†
        replacements = {
            'commit-guide.py': 'commit-guide',
            'post-commit-doc-gen.py': 'post-commit-docgen',
            'pre-commit-doc-gen.py': 'pre-commit-docgen',
            '.yml': '-yml',
            '.py': '-py',
            '.txt': '-txt',
            'fix()': 'fix',
            'feat()': 'feat',
            'docs()': 'docs',
        }
        
        for old, new in replacements.items():
            clean_message = clean_message.replace(old, new)
        
        # è½‰æ›ç‚ºæª”åæ ¼å¼
        name_part = re.sub(r'[^\w\s-]', ' ', clean_message)
        name_part = re.sub(r'\s+', '-', name_part.strip())
        name_part = name_part.lower()
        
        # ç§»é™¤é‡è¤‡çš„é€£å­—ç¬¦
        name_part = re.sub(r'-+', '-', name_part)
        name_part = name_part.strip('-')
        
        # é•·åº¦æ§åˆ¶
        if len(name_part) > 50:
            words = name_part.split('-')
            # ä¿ç•™é‡è¦è©å½™
            important_words = []
            for word in words:
                if len(word) > 2 and word not in ['and', 'the', 'for', 'with', 'from', 'into']:
                    important_words.append(word)
                if len('-'.join(important_words)) > 40:
                    break
            name_part = '-'.join(important_words[:6])
        
        # ç¢ºä¿æœ‰å…§å®¹
        if not name_part or len(name_part) < 3:
            name_part = f"{commit_type}-update"
        
        return f"{date_str}-{commit_type}-{name_part}.yml"
    
    def migrate_single_file(self, log_file: Path) -> bool:
        """é·ç§»å–®å€‹æª”æ¡ˆ"""
        print(f"\nğŸ“„ è™•ç†: {log_file.name}")
        
        try:
            # è®€å–ç¾æœ‰æ—¥èªŒ
            with open(log_file, 'r', encoding='utf-8') as f:
                log_data = yaml.safe_load(f)
            
            commit_hash = log_data.get('commit_hash')
            if not commit_hash or commit_hash == 'pending':
                print(f"  â­ï¸  è·³é: æ²’æœ‰ commit hash")
                self.skipped_count += 1
                return False
            
            # é‡æ–°è¨ˆç®—æ™‚é–“
            time_info = self.get_commit_time_by_log(commit_hash)
            old_time = log_data.get('metrics', {}).get('total_time_minutes', 0)
            
            print(f"  â±ï¸  æ™‚é–“: {old_time} â†’ {time_info['total']} åˆ†é˜ ({time_info['method']})")
            
            # æ›´æ–°æ™‚é–“è³‡è¨Š
            if 'timeline' in log_data and log_data['timeline']:
                log_data['timeline'][0]['duration'] = time_info['total']
                log_data['timeline'][0]['ai_time'] = time_info['ai']
                log_data['timeline'][0]['human_time'] = time_info['human']
            
            if 'metrics' not in log_data:
                log_data['metrics'] = {}
                
            log_data['metrics']['total_time_minutes'] = time_info['total']
            log_data['metrics']['ai_time_minutes'] = time_info['ai']
            log_data['metrics']['human_time_minutes'] = time_info['human']
            log_data['metrics']['time_estimation_method'] = time_info['method']
            log_data['metrics']['time_confidence'] = time_info['confidence']
            log_data['metrics']['migrated_at'] = datetime.now().isoformat()
            
            # æ›´æ–°ç™¾åˆ†æ¯”
            if time_info['total'] > 0:
                log_data['metrics']['ai_percentage'] = round(time_info['ai'] / time_info['total'] * 100, 1)
                log_data['metrics']['human_percentage'] = round(time_info['human'] / time_info['total'] * 100, 1)
            
            # ç”Ÿæˆæ–°æª”å
            new_filename = self.generate_clear_filename(log_data, commit_hash)
            new_filepath = log_file.parent / new_filename
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦æ”¹å
            renamed = False
            if new_filepath != log_file:
                if new_filepath.exists():
                    # é¿å…è¦†è“‹ï¼ŒåŠ ä¸Šåºè™Ÿ
                    base = new_filename.rsplit('.', 1)[0]
                    counter = 2
                    while new_filepath.exists():
                        new_filename = f"{base}-{counter}.yml"
                        new_filepath = log_file.parent / new_filename
                        counter += 1
                
                print(f"  ğŸ“ æ”¹å: â†’ {new_filename}")
                renamed = True
            
            # å¯«å…¥æ›´æ–°å…§å®¹
            with open(new_filepath, 'w', encoding='utf-8') as f:
                yaml.dump(log_data, f, allow_unicode=True, sort_keys=False)
            
            # åˆªé™¤èˆŠæª”æ¡ˆ
            if renamed and new_filepath != log_file:
                log_file.unlink()
            
            self.migrated_count += 1
            return True
            
        except Exception as e:
            print(f"  âŒ éŒ¯èª¤: {e}")
            self.error_count += 1
            return False
    
    def run(self, specific_files: Optional[List[str]] = None):
        """åŸ·è¡Œé·ç§»"""
        print("ğŸš€ é–‹ç™¼æ—¥èªŒé·ç§» v2")
        print(f"ğŸ“ ç›®éŒ„: {self.dev_logs_dir}")
        print("=" * 50)
        
        # æ±ºå®šè¦è™•ç†çš„æª”æ¡ˆ
        if specific_files:
            log_files = [self.dev_logs_dir / f for f in specific_files if (self.dev_logs_dir / f).exists()]
        else:
            log_files = list(self.dev_logs_dir.glob("*.yml"))
            # æ’é™¤ template æª”æ¡ˆ
            log_files = [f for f in log_files if 'template' not in f.name]
        
        total = len(log_files)
        print(f"ğŸ“Š å°‡è™•ç† {total} å€‹æª”æ¡ˆ\n")
        
        # è™•ç†æ¯å€‹æª”æ¡ˆ
        for i, log_file in enumerate(log_files, 1):
            print(f"é€²åº¦: [{i}/{total}]", end='')
            self.migrate_single_file(log_file)
        
        # ç¸½çµ
        print("\n" + "=" * 50)
        print("âœ… é·ç§»å®Œæˆ!")
        print(f"   æˆåŠŸ: {self.migrated_count}")
        print(f"   è·³é: {self.skipped_count}")
        print(f"   éŒ¯èª¤: {self.error_count}")

if __name__ == "__main__":
    migration = DevLogMigrationV2()
    
    # å¦‚æœæœ‰åƒæ•¸ï¼Œåªè™•ç†æŒ‡å®šæª”æ¡ˆ
    if len(sys.argv) > 1:
        migration.run(sys.argv[1:])
    else:
        migration.run()