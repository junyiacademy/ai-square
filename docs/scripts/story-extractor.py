#!/usr/bin/env python3
"""
æ•…äº‹èƒå–å™¨ - å¾ç¥¨åˆ¸ä¸­æå–æœ‰åƒ¹å€¼çš„ç¶“é©—å’ŒçŸ¥è­˜
"""

import os
import yaml
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List

class StoryExtractor:
    """å¾é–‹ç™¼éç¨‹ä¸­èƒå–æ•…äº‹å’Œç¶“é©—"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.docs_dir = self.project_root / "docs"
        
    def extract_story(self, ticket_path: Path) -> Dict:
        """å¾ç¥¨åˆ¸èƒå–æ•…äº‹"""
        
        with open(ticket_path, 'r', encoding='utf-8') as f:
            ticket_data = yaml.safe_load(f)
        
        # å¾æ•´åˆå¼ç¥¨åˆ¸ä¸­ç›´æ¥è®€å–
        devlog_data = ticket_data.get('dev_log', {})
        test_data = ticket_data.get('test_report', {})
        
        # èƒå–æ•…äº‹å…ƒç´ 
        story = {
            'ticket_id': ticket_data['id'],
            'ticket_name': ticket_data['name'],
            'type': ticket_data['type'],
            'created_at': datetime.now().isoformat(),
            
            # 1. ç”¢å“æ´å¯Ÿ
            'product_insights': {
                'feature': ticket_data.get('spec', {}).get('feature'),
                'purpose': ticket_data.get('spec', {}).get('purpose'),
                'user_value': self._extract_user_value(ticket_data),
                'acceptance_criteria': ticket_data.get('spec', {}).get('acceptance_criteria', [])
            },
            
            # 2. æŠ€è¡“æŒ‘æˆ°å’Œè§£æ±ºæ–¹æ¡ˆ
            'technical_insights': {
                'challenges': self._extract_challenges(devlog_data),
                'solutions': self._extract_solutions(devlog_data),
                'decisions': self._extract_decisions(devlog_data),
                'patterns_used': self._extract_patterns(ticket_data)
            },
            
            # 3. é–‹ç™¼æ•ˆç‡æŒ‡æ¨™
            'efficiency_metrics': {
                'duration_minutes': ticket_data.get('time_tracking', {}).get('actual_duration_minutes', 0),
                'ai_time_minutes': ticket_data.get('time_tracking', {}).get('ai_time_minutes', 0),
                'human_time_minutes': ticket_data.get('time_tracking', {}).get('human_time_minutes', 0),
                'ai_efficiency_ratio': self._calculate_ai_efficiency(ticket_data),
                'test_coverage': test_data.get('coverage', {}),
                'files_changed': len(ticket_data.get('development', {}).get('files_changed', []))
            },
            
            # 4. AI å”ä½œç¶“é©—
            'ai_collaboration': {
                'total_interactions': ticket_data.get('ai_usage', {}).get('total_interactions', 0),
                'estimated_cost': ticket_data.get('ai_usage', {}).get('estimated_cost_usd', 0),
                'complexity_breakdown': ticket_data.get('ai_usage', {}).get('complexity_breakdown', {}),
                'cost_per_feature': self._calculate_cost_per_feature(ticket_data)
            },
            
            # 5. å­¸ç¿’è¦é»
            'learnings': {
                'what_worked_well': [],
                'what_could_improve': [],
                'reusable_patterns': [],
                'avoid_in_future': []
            },
            
            # 6. å¯é‡ç”¨è³‡ç”¢
            'reusable_assets': {
                'code_snippets': self._extract_code_snippets(ticket_data),
                'test_patterns': self._extract_test_patterns(test_data),
                'configuration': self._extract_config_patterns(ticket_data)
            }
        }
        
        # åŸºæ–¼æ•¸æ“šè‡ªå‹•å¡«å……å­¸ç¿’è¦é»
        story['learnings'] = self._auto_extract_learnings(story)
        
        return story
    
    def _extract_user_value(self, ticket_data: Dict) -> str:
        """æå–ç”¨æˆ¶åƒ¹å€¼"""
        purpose = ticket_data.get('spec', {}).get('purpose', '')
        if purpose and purpose != '[è«‹æè¿°ç›®çš„]':
            return purpose
        return "å¾…åˆ†æ"
    
    def _extract_challenges(self, devlog_data: Dict) -> List[Dict]:
        """æå–æŠ€è¡“æŒ‘æˆ°"""
        challenges = []
        for session in devlog_data.get('sessions', []):
            for challenge in session.get('challenges', []):
                challenges.append({
                    'description': challenge.get('description', challenge) if isinstance(challenge, dict) else challenge,
                    'session': session.get('session_id')
                })
        return challenges
    
    def _extract_solutions(self, devlog_data: Dict) -> List[Dict]:
        """æå–è§£æ±ºæ–¹æ¡ˆ"""
        solutions = []
        for session in devlog_data.get('sessions', []):
            for activity in session.get('activities', []):
                # è™•ç† dict æˆ– string æ ¼å¼
                activity_text = activity.get('action', '') if isinstance(activity, dict) else str(activity)
                if any(keyword in activity_text.lower() for keyword in ['è§£æ±º', 'ä¿®å¾©', 'fix', 'solve', 'å¯¦ä½œ', 'å®Œæˆ']):
                    solutions.append({
                        'description': activity_text,
                        'session': session.get('session_id')
                    })
        return solutions
    
    def _extract_decisions(self, devlog_data: Dict) -> List[Dict]:
        """æå–é—œéµæ±ºç­–"""
        decisions = []
        for session in devlog_data.get('sessions', []):
            for decision in session.get('decisions', []):
                decisions.append({
                    'description': decision.get('description', decision) if isinstance(decision, dict) else decision,
                    'session': session.get('session_id')
                })
        return decisions
    
    def _extract_patterns(self, ticket_data: Dict) -> List[str]:
        """æå–ä½¿ç”¨çš„è¨­è¨ˆæ¨¡å¼"""
        patterns = []
        files_changed = ticket_data.get('development', {}).get('files_changed', [])
        
        # åŸºæ–¼æ–‡ä»¶é¡å‹æ¨æ¸¬æ¨¡å¼
        for file in files_changed:
            if 'context' in file.lower():
                patterns.append('React Context Pattern')
            if 'hook' in file.lower():
                patterns.append('Custom Hook Pattern')
            if 'provider' in file.lower():
                patterns.append('Provider Pattern')
            if 'factory' in file.lower():
                patterns.append('Factory Pattern')
            if 'singleton' in file.lower():
                patterns.append('Singleton Pattern')
        
        return list(set(patterns))
    
    def _calculate_ai_efficiency(self, ticket_data: Dict) -> float:
        """è¨ˆç®— AI æ•ˆç‡æ¯”"""
        ai_time = ticket_data.get('time_tracking', {}).get('ai_time_minutes', 0)
        total_time = ticket_data.get('time_tracking', {}).get('actual_duration_minutes', 1)
        if total_time > 0:
            return round(ai_time / total_time, 2)
        return 0.0
    
    def _calculate_cost_per_feature(self, ticket_data: Dict) -> float:
        """è¨ˆç®—æ¯å€‹åŠŸèƒ½çš„æˆæœ¬"""
        total_cost = ticket_data.get('ai_usage', {}).get('estimated_cost_usd', 0)
        criteria_count = len(ticket_data.get('spec', {}).get('acceptance_criteria', [1]))
        return round(total_cost / criteria_count, 4)
    
    def _extract_code_snippets(self, ticket_data: Dict) -> List[Dict]:
        """æå–å¯é‡ç”¨çš„ä»£ç¢¼ç‰‡æ®µ"""
        # é€™è£¡å¯ä»¥é€²ä¸€æ­¥åˆ†æ git diff ä¾†æå–å¯¦éš›ä»£ç¢¼
        return []
    
    def _extract_test_patterns(self, test_data: Dict) -> List[str]:
        """æå–æ¸¬è©¦æ¨¡å¼"""
        patterns = []
        if test_data.get('summary', {}).get('total_tests', 0) > 0:
            patterns.append('Unit Testing')
        return patterns
    
    def _extract_config_patterns(self, ticket_data: Dict) -> List[str]:
        """æå–é…ç½®æ¨¡å¼"""
        patterns = []
        files_changed = ticket_data.get('development', {}).get('files_changed', [])
        
        for file in files_changed:
            if 'config' in file.lower() or '.json' in file or '.yml' in file:
                patterns.append(f'Configuration: {Path(file).name}')
        
        return patterns
    
    def _auto_extract_learnings(self, story: Dict) -> Dict:
        """è‡ªå‹•æå–å­¸ç¿’è¦é»"""
        learnings = {
            'what_worked_well': [],
            'what_could_improve': [],
            'reusable_patterns': [],
            'avoid_in_future': []
        }
        
        # åŸºæ–¼æ•ˆç‡æŒ‡æ¨™
        efficiency = story['efficiency_metrics']
        if efficiency['ai_efficiency_ratio'] > 0.5:
            learnings['what_worked_well'].append('é«˜æ•ˆçš„ AI å”ä½œï¼ˆAI æ™‚é–“ä½”æ¯” > 50%ï¼‰')
        
        if efficiency['test_coverage'].get('lines', 0) > 80:
            learnings['what_worked_well'].append('å„ªç§€çš„æ¸¬è©¦è¦†è“‹ç‡ï¼ˆ> 80%ï¼‰')
        
        # åŸºæ–¼æˆæœ¬
        ai_collab = story['ai_collaboration']
        if ai_collab['cost_per_feature'] < 0.1:
            learnings['what_worked_well'].append('æˆæœ¬æ•ˆç›Šé«˜ï¼ˆæ¯åŠŸèƒ½ < $0.10ï¼‰')
        elif ai_collab['cost_per_feature'] > 1.0:
            learnings['what_could_improve'].append('é™ä½ AI ä½¿ç”¨æˆæœ¬')
        
        # åŸºæ–¼æŒ‘æˆ°
        if len(story['technical_insights']['challenges']) > 3:
            learnings['what_could_improve'].append('æ¸›å°‘æŠ€è¡“å‚µå‹™å’Œè¤‡é›œåº¦')
        
        # å¯é‡ç”¨æ¨¡å¼
        if story['technical_insights']['patterns_used']:
            learnings['reusable_patterns'].extend(story['technical_insights']['patterns_used'])
        
        return learnings
    
    def save_story(self, story: Dict, ticket_path: Path) -> Path:
        """ä¿å­˜æ•…äº‹"""
        ticket_name = Path(ticket_path).stem
        story_dir = self.docs_dir / "stories" / datetime.now().strftime('%Y-%m')
        story_dir.mkdir(parents=True, exist_ok=True)
        
        story_file = story_dir / f"{ticket_name}-story.yml"
        
        with open(story_file, 'w', encoding='utf-8') as f:
            yaml.dump(story, f, default_flow_style=False, allow_unicode=True)
        
        # åŒæ™‚ç”Ÿæˆ Markdown ç‰ˆæœ¬
        md_file = story_file.with_suffix('.md')
        self._generate_markdown_story(story, md_file)
        
        return story_file
    
    def _generate_markdown_story(self, story: Dict, output_path: Path):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„æ•…äº‹"""
        content = f"""# {story['ticket_name']} é–‹ç™¼æ•…äº‹

## ğŸ“‹ æ¦‚è¿°
- **é¡å‹**: {story['type']}
- **åŠŸèƒ½**: {story['product_insights']['feature']}
- **ç›®çš„**: {story['product_insights']['purpose']}

## ğŸ¯ ç”¢å“åƒ¹å€¼
{story['product_insights']['user_value']}

### é©—æ”¶æ¨™æº–
{chr(10).join(f"- {c}" for c in story['product_insights']['acceptance_criteria'])}

## ğŸ’¡ æŠ€è¡“æ´å¯Ÿ

### é‡åˆ°çš„æŒ‘æˆ°
{chr(10).join(f"- {c['description']}" for c in story['technical_insights']['challenges'])}

### è§£æ±ºæ–¹æ¡ˆ
{chr(10).join(f"- {s['description']}" for s in story['technical_insights']['solutions'])}

### é—œéµæ±ºç­–
{chr(10).join(f"- {d['description']}" for d in story['technical_insights']['decisions'])}

### ä½¿ç”¨çš„æ¨¡å¼
{chr(10).join(f"- {p}" for p in story['technical_insights']['patterns_used'])}

## ğŸ“Š æ•ˆç‡æŒ‡æ¨™
- **ç¸½æ™‚é•·**: {story['efficiency_metrics']['duration_minutes']} åˆ†é˜
- **AI æ™‚é–“**: {story['efficiency_metrics']['ai_time_minutes']} åˆ†é˜
- **AI æ•ˆç‡**: {story['efficiency_metrics']['ai_efficiency_ratio'] * 100:.1f}%
- **æ–‡ä»¶è®Šæ›´**: {story['efficiency_metrics']['files_changed']} å€‹

## ğŸ¤– AI å”ä½œ
- **äº’å‹•æ¬¡æ•¸**: {story['ai_collaboration']['total_interactions']}
- **ä¼°ç®—æˆæœ¬**: ${story['ai_collaboration']['estimated_cost']:.2f}
- **æ¯åŠŸèƒ½æˆæœ¬**: ${story['ai_collaboration']['cost_per_feature']:.4f}

## ğŸ“š å­¸ç¿’è¦é»

### âœ… åšå¾—å¥½çš„åœ°æ–¹
{chr(10).join(f"- {item}" for item in story['learnings']['what_worked_well'])}

### ğŸ“ˆ å¯ä»¥æ”¹é€²çš„åœ°æ–¹
{chr(10).join(f"- {item}" for item in story['learnings']['what_could_improve'])}

### ğŸ”„ å¯é‡ç”¨æ¨¡å¼
{chr(10).join(f"- {item}" for item in story['learnings']['reusable_patterns'])}

### âš ï¸ æœªä¾†è¦é¿å…
{chr(10).join(f"- {item}" for item in story['learnings']['avoid_in_future'])}

---
*è‡ªå‹•ç”Ÿæˆæ–¼ {story['created_at']}*
"""
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)


def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•…äº‹èƒå–å™¨')
    parser.add_argument('--ticket', help='ç¥¨åˆ¸è·¯å¾‘')
    parser.add_argument('--format', choices=['yaml', 'markdown', 'both'], 
                       default='both', help='è¼¸å‡ºæ ¼å¼')
    
    args = parser.parse_args()
    
    extractor = StoryExtractor()
    
    # æ‰¾åˆ°æ´»èºç¥¨åˆ¸
    if not args.ticket:
        active_dir = extractor.docs_dir / "tickets" / "active"
        tickets = list(active_dir.glob("*.yml"))
        if tickets:
            args.ticket = tickets[0]
        else:
            print("âŒ æ²’æœ‰æ‰¾åˆ°æ´»èºçš„ç¥¨åˆ¸")
            return
    
    # èƒå–æ•…äº‹
    story = extractor.extract_story(Path(args.ticket))
    
    # ä¿å­˜æ•…äº‹
    story_file = extractor.save_story(story, Path(args.ticket))
    
    print(f"âœ… æ•…äº‹å·²èƒå–ä¸¦ä¿å­˜åˆ°:")
    print(f"   - YAML: {story_file}")
    print(f"   - Markdown: {story_file.with_suffix('.md')}")
    
    # é¡¯ç¤ºæ‘˜è¦
    print(f"\nğŸ“Š æ‘˜è¦:")
    print(f"   - AI æ•ˆç‡: {story['efficiency_metrics']['ai_efficiency_ratio'] * 100:.1f}%")
    print(f"   - ç¸½æˆæœ¬: ${story['ai_collaboration']['estimated_cost']:.2f}")
    print(f"   - å­¸åˆ° {len(story['learnings']['reusable_patterns'])} å€‹å¯é‡ç”¨æ¨¡å¼")


if __name__ == '__main__':
    main()