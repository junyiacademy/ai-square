#!/usr/bin/env python3
"""
Reorganize dev logs:
1. Add commit timestamp to filename
2. Improve titles and filenames
3. Group similar logs by date into folders
"""

import os
import subprocess
import yaml
import re
import shutil
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict

class DevLogReorganizer:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.dev_logs_dir = self.project_root / "docs" / "dev-logs"
        self.processed_count = 0
        self.error_count = 0
        
    def run_command(self, cmd: List[str]) -> Tuple[int, str, str]:
        """åŸ·è¡Œå‘½ä»¤ä¸¦è¿”å›çµæœ"""
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            cwd=self.project_root
        )
        return result.returncode, result.stdout, result.stderr
    
    def get_commit_details(self, commit_hash: str) -> Optional[Dict]:
        """ç²å– commit çš„è©³ç´°è³‡è¨ŠåŒ…æ‹¬æ™‚é–“"""
        # ç²å– commit æ™‚é–“å’Œè¨Šæ¯
        code, output, _ = self.run_command([
            "git", "show", 
            "--no-patch",
            "--format=%ct|%s|%b",
            commit_hash
        ])
        
        if code != 0:
            return None
            
        parts = output.strip().split('|', 2)
        if len(parts) < 2:
            return None
            
        timestamp = int(parts[0])
        subject = parts[1]
        body = parts[2] if len(parts) > 2 else ""
        
        commit_time = datetime.fromtimestamp(timestamp)
        
        return {
            'time': commit_time,
            'subject': subject,
            'body': body,
            'full_message': f"{subject}\n{body}".strip()
        }
    
    def improve_title(self, log_data: Dict, commit_info: Dict) -> str:
        """ç”Ÿæˆæ›´å¥½çš„æ¨™é¡Œ"""
        # å¾ commit è¨Šæ¯æå–æ ¸å¿ƒå…§å®¹
        subject = commit_info['subject']
        
        # ç§»é™¤ conventional commit å‰ç¶´
        clean_subject = re.sub(r'^(feat|fix|docs|refactor|test|chore|improve)\([^)]*\):\s*', '', subject)
        
        # ç‰¹æ®Šæƒ…æ³è™•ç†
        if 'migration' in clean_subject.lower() or 'migrate' in clean_subject.lower():
            if 'dev logs' in clean_subject.lower():
                return "Migrate dev logs with accurate time calculation"
            else:
                return clean_subject
        
        # å¦‚æœè¨Šæ¯å·²ç¶“å¾ˆæ¸…æ¥šï¼Œç›´æ¥ä½¿ç”¨
        if len(clean_subject) > 10 and len(clean_subject) < 80:
            return clean_subject
        
        # å¦å‰‡åŸºæ–¼æª”æ¡ˆè®Šæ›´ç”Ÿæˆ
        changes = log_data.get('changes', {})
        total_files = (len(changes.get('added', [])) + 
                      len(changes.get('modified', [])) + 
                      len(changes.get('deleted', [])))
        
        if total_files == 1:
            # å–®æª”æ¡ˆï¼Œä½¿ç”¨æª”å
            if changes.get('added'):
                filename = Path(changes['added'][0]).stem
                return f"Add {filename}"
            elif changes.get('modified'):
                filename = Path(changes['modified'][0]).stem
                return f"Update {filename}"
            elif changes.get('deleted'):
                filename = Path(changes['deleted'][0]).stem
                return f"Remove {filename}"
        
        return clean_subject
    
    def generate_improved_filename(self, log_data: Dict, commit_info: Dict) -> str:
        """ç”ŸæˆåŒ…å«æ™‚é–“æˆ³çš„æ”¹é€²æª”å"""
        commit_time = commit_info['time']
        date_str = commit_time.strftime('%Y-%m-%d')
        time_str = commit_time.strftime('%H-%M-%S')
        
        commit_type = log_data.get('type', 'other')
        
        # å¾æ¨™é¡Œç”Ÿæˆç°¡æ½”çš„åç¨±éƒ¨åˆ†
        title = self.improve_title(log_data, commit_info)
        
        # è½‰æ›ç‚ºæª”åæ ¼å¼
        name_part = re.sub(r'[^\w\s-]', ' ', title)
        name_part = re.sub(r'\s+', '-', name_part.strip())
        name_part = name_part.lower()
        
        # ç§»é™¤å†—é¤˜è©
        redundant_words = ['the', 'and', 'for', 'with', 'from', 'into', 'update', 'add', 'remove']
        words = name_part.split('-')
        filtered_words = [w for w in words if w and w not in redundant_words]
        
        # é™åˆ¶é•·åº¦
        if len('-'.join(filtered_words)) > 40:
            name_part = '-'.join(filtered_words[:5])
        else:
            name_part = '-'.join(filtered_words)
        
        name_part = re.sub(r'-+', '-', name_part).strip('-')
        
        # ç¢ºä¿æœ‰å…§å®¹
        if not name_part:
            name_part = commit_type
        
        return f"{date_str}-{time_str}-{commit_type}-{name_part}.yml"
    
    def categorize_logs(self, logs_by_date: Dict[str, List[Dict]]) -> Dict[str, Dict[str, List[Dict]]]:
        """å°‡åŒä¸€å¤©çš„æ—¥èªŒæŒ‰é¡å‹åˆ†çµ„"""
        categorized = {}
        
        for date_str, logs in logs_by_date.items():
            categories = defaultdict(list)
            
            for log_info in logs:
                log_data = log_info['data']
                commit_type = log_data.get('type', 'other')
                
                # ç‰¹æ®Šåˆ†é¡
                if 'time' in str(log_info['path']).lower() or 'tracking' in str(log_info['path']).lower():
                    category = 'time-tracking'
                elif 'migration' in str(log_info['path']).lower() or 'migrate' in str(log_info['path']).lower():
                    category = 'migrations'
                elif 'auto-generated' in log_data.get('description', '').lower():
                    category = 'auto-documentation'
                elif commit_type == 'docs':
                    category = 'documentation'
                elif commit_type == 'bug' or commit_type == 'fix':
                    category = 'bugfixes'
                elif commit_type == 'feat' or commit_type == 'feature':
                    category = 'features'
                elif commit_type == 'refactor':
                    category = 'refactoring'
                else:
                    category = 'misc'
                
                categories[category].append(log_info)
            
            categorized[date_str] = dict(categories)
        
        return categorized
    
    def process_log_file(self, log_file: Path) -> Optional[Dict]:
        """è™•ç†å–®å€‹æ—¥èªŒæª”æ¡ˆ"""
        try:
            # è®€å–æ—¥èªŒ
            with open(log_file, 'r', encoding='utf-8') as f:
                log_data = yaml.safe_load(f)
            
            commit_hash = log_data.get('commit_hash')
            if not commit_hash or commit_hash == 'pending':
                print(f"â­ï¸  è·³é {log_file.name}: æ²’æœ‰ commit hash")
                return None
            
            # ç²å– commit è©³ç´°è³‡è¨Š
            commit_info = self.get_commit_details(commit_hash)
            if not commit_info:
                print(f"âš ï¸  ç„¡æ³•ç²å– commit è³‡è¨Š: {log_file.name}")
                return None
            
            # æ”¹é€²æ¨™é¡Œ
            improved_title = self.improve_title(log_data, commit_info)
            log_data['title'] = improved_title
            
            # ç”Ÿæˆæ–°æª”å
            new_filename = self.generate_improved_filename(log_data, commit_info)
            
            return {
                'path': log_file,
                'data': log_data,
                'new_filename': new_filename,
                'commit_info': commit_info,
                'date': commit_info['time'].strftime('%Y-%m-%d')
            }
            
        except Exception as e:
            print(f"âŒ è™•ç†éŒ¯èª¤ {log_file.name}: {e}")
            self.error_count += 1
            return None
    
    def run(self):
        """åŸ·è¡Œé‡çµ„"""
        print("ğŸš€ é–‹å§‹é‡çµ„é–‹ç™¼æ—¥èªŒ...")
        print(f"ğŸ“ ç›®éŒ„: {self.dev_logs_dir}")
        print("=" * 50)
        
        # ç²å–æ‰€æœ‰ yml æª”æ¡ˆ
        log_files = list(self.dev_logs_dir.glob("*.yml"))
        # æ’é™¤ template å’Œ README
        log_files = [f for f in log_files if 'template' not in f.name.lower() and f.name != 'README.md']
        
        total = len(log_files)
        print(f"ğŸ“Š æ‰¾åˆ° {total} å€‹æ—¥èªŒæª”æ¡ˆ\n")
        
        # è™•ç†æ¯å€‹æª”æ¡ˆ
        logs_by_date = defaultdict(list)
        
        for i, log_file in enumerate(log_files, 1):
            print(f"è™•ç†é€²åº¦: [{i}/{total}] {log_file.name}")
            result = self.process_log_file(log_file)
            if result:
                logs_by_date[result['date']].append(result)
        
        print("\n" + "=" * 50)
        print("ğŸ“‚ é–‹å§‹çµ„ç¹”æª”æ¡ˆ...")
        
        # æŒ‰æ—¥æœŸå’Œé¡åˆ¥çµ„ç¹”
        categorized = self.categorize_logs(logs_by_date)
        
        # å‰µå»ºç›®éŒ„çµæ§‹ä¸¦ç§»å‹•æª”æ¡ˆ
        for date_str, categories in categorized.items():
            date_dir = self.dev_logs_dir / date_str
            
            # å¦‚æœåªæœ‰ä¸€å€‹é¡åˆ¥ä¸”æª”æ¡ˆå°‘æ–¼3å€‹ï¼Œä¸å‰µå»ºå­ç›®éŒ„
            total_files = sum(len(logs) for logs in categories.values())
            if len(categories) == 1 and total_files <= 3:
                # ç›´æ¥æ”¾åœ¨ dev-logs ç›®éŒ„
                for category, logs in categories.items():
                    for log_info in logs:
                        self._move_log_file(log_info, self.dev_logs_dir)
            else:
                # å‰µå»ºæ—¥æœŸç›®éŒ„
                date_dir.mkdir(exist_ok=True)
                print(f"\nğŸ“… {date_str} ({total_files} å€‹æª”æ¡ˆ)")
                
                for category, logs in categories.items():
                    if len(logs) >= 2:  # åªæœ‰2å€‹æˆ–ä»¥ä¸Šæ‰å‰µå»ºå­ç›®éŒ„
                        category_dir = date_dir / category
                        category_dir.mkdir(exist_ok=True)
                        print(f"  ğŸ“ {category} ({len(logs)} å€‹æª”æ¡ˆ)")
                        
                        for log_info in logs:
                            self._move_log_file(log_info, category_dir)
                    else:
                        # å–®å€‹æª”æ¡ˆç›´æ¥æ”¾åœ¨æ—¥æœŸç›®éŒ„
                        for log_info in logs:
                            self._move_log_file(log_info, date_dir)
        
        # ç¸½çµ
        print("\n" + "=" * 50)
        print("âœ… é‡çµ„å®Œæˆ!")
        print(f"   è™•ç†: {self.processed_count} å€‹æª”æ¡ˆ")
        print(f"   éŒ¯èª¤: {self.error_count} å€‹")
    
    def _move_log_file(self, log_info: Dict, target_dir: Path):
        """ç§»å‹•ä¸¦æ›´æ–°æ—¥èªŒæª”æ¡ˆ"""
        try:
            old_path = log_info['path']
            new_path = target_dir / log_info['new_filename']
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦é¿å…è¦†è“‹
            if new_path.exists() and new_path != old_path:
                base = log_info['new_filename'].rsplit('.', 1)[0]
                counter = 2
                while new_path.exists():
                    new_filename = f"{base}-{counter}.yml"
                    new_path = target_dir / new_filename
                    counter += 1
            
            # æ›´æ–°æª”æ¡ˆå…§å®¹
            with open(new_path, 'w', encoding='utf-8') as f:
                yaml.dump(log_info['data'], f, allow_unicode=True, sort_keys=False)
            
            # å¦‚æœæ˜¯ä¸åŒè·¯å¾‘ï¼Œåˆªé™¤èˆŠæª”æ¡ˆ
            if new_path != old_path:
                old_path.unlink()
                print(f"    âœ… {old_path.name} â†’ {new_path.relative_to(self.dev_logs_dir)}")
            
            self.processed_count += 1
            
        except Exception as e:
            print(f"    âŒ ç§»å‹•å¤±æ•—: {e}")
            self.error_count += 1

if __name__ == "__main__":
    reorganizer = DevLogReorganizer()
    reorganizer.run()