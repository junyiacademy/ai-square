# PBL 評估系統測試指南

## 改進摘要
PBL 評估系統已經過調整，使其更適合開放式學習任務。主要改進包括：

### 1. 評分標準調整
- **舊版**: 簡單打招呼 = 0-20 分（過於嚴苛）
- **新版**: 簡單打招呼 = 20-40 分（基礎參與）

### 2. 評估原則更新
- 重視學習過程而非只看結果
- 根據任務類型（研究/分析/創作/練習）採用不同標準
- 互動品質比數量更重要

### 3. AI 評估者改進
- 從「嚴格但公平」改為「支持性且公平」
- 提供更多建設性反饋
- 溫度參數從 0.1 提高到 0.3

## 測試步驟

### 準備工作
1. 啟動開發伺服器：`cd frontend && npm run dev`
2. 登入系統（使用測試帳號）
3. 進入 PBL 學習頁面

### 測試場景

#### 場景 1：最小參與測試
**目的**: 驗證簡單互動不會得到過低分數

1. 選擇「AI 輔助求職訓練」場景
2. 在第一個任務中只輸入：
   - "Hi"
   - "I want to learn about this"
3. 點擊「完成並評估」
4. **預期結果**: 獲得 20-40 分（而非舊版的 0-20 分）

#### 場景 2：基礎提問測試
**目的**: 驗證提出問題就能獲得合理分數

1. 在任務中提出 2-3 個相關問題：
   - "What are the current AI trends?"
   - "How can I use AI for job searching?"
   - "Can you give me some examples?"
2. 點擊「完成並評估」
3. **預期結果**: 獲得 40-60 分

#### 場景 3：深度探索測試
**目的**: 驗證深入探討能獲得高分

1. 進行深度對話：
   - 提出具體問題
   - 要求詳細說明
   - 展現批判性思考
   - 總結學到的內容
2. 點擊「完成並評估」
3. **預期結果**: 獲得 60-90 分

### 評估反饋檢查
確認反饋內容：
- ✅ 是否包含正面鼓勵
- ✅ 是否提供具體改進建議
- ✅ 是否標註相關 KSA 代碼
- ✅ 語氣是否支持性而非批判性

## 對比測試結果

### 改進前後對比
| 學習者行為 | 舊版評分 | 新版評分 | 改進幅度 |
|-----------|---------|---------|---------|
| 只打招呼 | 0-20分 | 20-40分 | +20分 |
| 簡單提問 | 20-50分 | 40-60分 | +15分 |
| 認真探索 | 50-70分 | 60-75分 | +8分 |
| 深度學習 | 70-85分 | 75-90分 | +5分 |

### 反饋語氣對比
**舊版**: "學習者只是打招呼，沒有嘗試解決任務"
**新版**: "學習者展現了參與的意願，建議可以提出更多具體問題來深入探索"

## 注意事項
1. 評分仍保持客觀性，但更加鼓勵性
2. 不同任務類型會有不同的評估重點
3. 研究型任務特別重視探索過程
4. 系統會根據學習者的語言提供相應語言的反饋

## 問題回報
如發現評估系統問題，請記錄：
- 輸入的對話內容
- 獲得的分數
- 反饋內容
- 預期與實際的差異

測試日期：_______________
測試人員：_______________