scenario_info:
  id: deep-learning-mlp-intro
  difficulty: beginner
  estimated_duration: 90
  target_domains:
  - engaging_with_ai
  - creating_with_ai
  - managing_with_ai
  title: 探索神經網路：手寫數字辨識入門
  description: 了解人工智慧如何透過模擬生物大腦結構的神經網路來辨識複雜模式，例如手寫數字。本課程將深入解析神經元、激勵值、權重和偏置的運作原理。
  prerequisites:
  - 對 AI/機器學習有基本的好奇心
  - 了解數字 0 到 1 之間的數學概念
  - '推薦：觀看 3Blue1Brown 神經網路視覺化影片 - https://www.youtube.com/watch?v=aircAruvnKk'
  learning_objectives:
  - 能夠定義神經元、激勵值、權重與偏置
  - 描述多層感知機 (MLP) 的層狀結構，包含輸入層、隱藏層和輸出層
  - 解釋激勵值如何從一層傳遞到下一層，並透過加權總和計算其變化
  - 認識激勵函數（如 Sigmoid 和 ReLU）在神經網路中的作用
  - 了解權重和偏置是如何影響神經網路的決策，並作為學習過程中的調整參數
ksa_mapping:
  knowledge:
  - K1.1
  - K2.1
  skills:
  - S1.1
  - S2.3
  attitudes:
  - A1.1
  - A2.1
tasks:
- id: task-1-structure
  category: learning
  time_limit: 20
  KSA_focus:
    primary:
    - K1.1
    - S1.1
    secondary:
    - A1.1
  ai_module:
    role: educator
    model: gemini-2.5-flash
    persona: 神經網路概念助理
    initial_prompt: '你是一位神經網路概念助理，幫助學生探索多層感知機 (MLP) 的基本構造。

      你的目標是引導他們理解：

      - 神經元在網路中的角色，以及它們承載的「激勵值」（0 到 1 之間的數字）

      - 輸入層、隱藏層和輸出層的區別和功能

      - 如何將一個 28x28 像素的圖像轉換成輸入層的 784 個神經元激勵值

      - 輸出層的 10 個神經元如何表示最終的數字判斷結果

      請使用清晰的視覺化描述，並鼓勵學生想像激勵值傳遞的過程。

      '
  title: 了解神經網路的層次與神經元
  description: 探索神經網路的三層結構（輸入、隱藏、輸出），並理解「激勵值」如何代表資訊。
  instructions: '定義神經元與激勵值。描述手寫數字辨識網路中，784 個輸入神經元和 10 個輸出神經元的作用。討論隱藏層神經元可能扮演的角色（例如：識別筆劃或邊緣）。

    '
  expected_outcome: 對多層感知機的結構及其元件功能有清晰的理解
- id: task-2-parameters
  category: learning
  time_limit: 30
  KSA_focus:
    primary:
    - K2.1
    - S1.1
    secondary:
    - S2.3
  ai_module:
    role: educator
    model: gemini-2.5-flash
    persona: 數學導師
    initial_prompt: '你是一位數學導師，專門協助學生理解神經網路中的權重和偏置。

      你的任務是：

      - 用簡單的數學範例說明加權總和的計算過程

      - 幫助學生理解偏置如何「調整」激勵閾值

      - 引導他們思考：如果改變某個權重，會如何影響輸出結果

      - 解釋梯度下降如何逐步調整這些參數以最小化誤差

      請確保使用清晰的數學表達式，但避免過於複雜的公式，保持直覺性。

      '
  title: 探索權重與偏置的作用
  description: 深入了解權重和偏置如何決定神經元之間的連接強度，以及它們如何影響網路的學習過程。
  instructions: '解釋權重如何表示神經元之間的連接強度。描述偏置在調整神經元激勵閾值中的角色。計算一個簡單範例：給定輸入激勵值、權重和偏置，計算下一層的激勵值。討論在訓練過程中，權重和偏置如何被調整以改善網路性能。

    '
  expected_outcome: 能夠理解並計算權重、偏置對激勵值傳遞的影響，並認識它們在學習中的重要性
- id: task-3-activation-functions
  category: learning
  time_limit: 40
  KSA_focus:
    primary:
    - K1.1
    - K2.1
    secondary:
    - A2.1
    - S2.3
  ai_module:
    role: educator
    model: gemini-2.5-flash
    persona: AI 研究導師
    initial_prompt: '你是一位 AI 研究導師，專注於幫助學生理解激勵函數的理論與實務。

      你的重點是：

      - 解釋線性疊加的局限性：為什麼純線性網路無法解決複雜問題

      - 介紹 Sigmoid、ReLU、Tanh 等常見激勵函數的數學形式和圖形

      - 討論「梯度消失」問題，以及為何 ReLU 在深度學習中更受歡迎

      - 在手寫數字辨識的脈絡下，說明 Softmax 如何將輸出轉換為概率分布

      鼓勵學生批判性思考：不同場景下應該選擇哪種激勵函數？

      '
  title: 認識激勵函數的重要性
  description: 探索激勵函數（如 Sigmoid、ReLU）如何為神經網路引入非線性，使其能夠學習複雜模式。
  instructions: '定義激勵函數，並解釋為何需要非線性轉換。比較 Sigmoid 和 ReLU 函數的特性與優缺點。視覺化理解：如果沒有激勵函數，神經網路會變成什麼樣子？討論在手寫數字辨識任務中，輸出層常使用 Softmax 函數的原因。

    '
  expected_outcome: 理解激勵函數在神經網路中的關鍵作用，並能比較不同函數的應用場景

completion_criteria:
  min_tasks_completed: 3
  required_competencies:
    - K1.1
    - K2.1
    - S1.1
  min_overall_score: 75

resources:
  - name: "3Blue1Brown 神經網路系列影片"
    url: "https://www.youtube.com/watch?v=aircAruvnKk"
    type: video
  - name: "神經網路與深度學習（免費線上書籍）"
    url: "http://neuralnetworksanddeeplearning.com/"
    type: reference
  - name: "MNIST 手寫數字資料庫"
    url: "http://yann.lecun.com/exdb/mnist/"
    type: reference
  - name: "深度學習基礎"
    url: "https://www.deeplearningbook.org/"
    type: guide

metadata:
  language: zhTW
  version: "1.0"
  last_updated: "2025-11-30"
  created_at: '2025-11-30T00:00:00Z'
  created_by: Claude AI Assistant
  tags:
    - neural-networks
    - deep-learning
    - mlp
    - computer-vision
    - mnist
